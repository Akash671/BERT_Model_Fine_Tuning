# -*- coding: utf-8 -*-
"""BERT_Model_Fine_Tuning_On_Twitter_Sentiment_Analysis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g6MMUYU2N0V_E0bgTFa0QAkIrbA8PnQ1
"""

import pandas as pd

df=pd.read_csv("/content/train.csv")

df.head()

test_df=pd.read_csv("/content/test.csv")

df.columns

df.head()

df[['retweets','likes','sentiment']].sample(20)

df.drop(['tweet_id', 'user_handle', 'timestamp', 'candidate', 'retweets', 'likes'],axis=1,inplace=True)

test_df.drop(['tweet_id', 'user_handle', 'timestamp', 'candidate', 'retweets', 'likes'],axis=1,inplace=True)

df.head()

df.shape

for row in range(500):
  df['tweet_text'][row]=df['party'][row]+" "+df['tweet_text'][row]

for row in range(50):
  test_df['tweet_text'][row]=test_df['party'][row]+" "+test_df['tweet_text'][row]

df.head()

df.drop('party',axis=1,inplace=True)

test_df.drop('party',axis=1,inplace=True)



df.head()

import re

def cleaning(data):
  # 1 lower case
  data=data.lower()
  #2 remove html tag
  data=re.sub(r'<.*?>','',data)
  #3 remove urls
  data=re.sub(r'http\S+|www\S+','',data)
  #4 remove emojies
  data=re.sub(r'[^\x00-\x7F]+',' ',data)
  #5 remove punchuations
  data=re.sub(r"[!]{2,}|[?]{2,}|[#]{2,}|[\-]{2,}", " ",data)
  #6 Remove special characters but keep words and basic punctuation
  clean_data = re.sub(r"[^\w\s.,!?]", "", data)

  return clean_data

df['text']=df['tweet_text'].apply(cleaning)
df.drop('tweet_text',axis=1,inplace=True)

test_df['text']=test_df['tweet_text'].apply(cleaning)
test_df.drop('tweet_text',axis=1,inplace=True)

def sentiment_cleaning(row):
  if row=='positive  ':
    return 'positive'
  else:
    return row

df['sentiment']=df['sentiment'].apply(sentiment_cleaning)

test_df['sentiment']=test_df['sentiment'].apply(sentiment_cleaning)

df.head()

test_df.head()

print(df["sentiment"].unique())

# lest convert df to transformer dataset format

from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments
from datasets import Dataset
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
import numpy as np

dataset = Dataset.from_pandas(df[['text', 'sentiment']])
dataset = dataset.rename_column("sentiment", "labels")
dataset = dataset.class_encode_column("labels")  # label â†’ class ids
dataset = dataset.train_test_split(test_size=0.2)

model_name = "bert-base-uncased"
tokenizer = BertTokenizerFast.from_pretrained(model_name)
# create token embedding
# add sepecial tokens
# add padding
# add masking
# add segment embedding
# add  positonal embedding
model = BertForSequenceClassification.from_pretrained(model_name, num_labels=3)

def tokenize(batch):
    return tokenizer(batch["text"], padding="max_length", truncation=True, max_length=128)

tokenized = dataset.map(tokenize, batched=True)

def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)

    precision, recall, f1, _ = precision_recall_fscore_support(
        labels, preds, average='weighted'  # or 'macro' if you want equal class importance
    )
    acc = accuracy_score(labels, preds)

    return {
        "accuracy": acc,
        "f1": f1,
        "precision": precision,
        "recall": recall
    }

training_args = TrainingArguments(
    output_dir="bert-sentiment-model",
    eval_strategy="epoch",
    save_strategy="epoch",
    logging_strategy="epoch",
    num_train_epochs=2,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    learning_rate=2e-5,
    weight_decay=0.01,
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized["train"],
    eval_dataset=tokenized["test"],
    tokenizer=tokenizer,
    compute_metrics=compute_metrics
)
trainer.train()

trainer.evaluate()



correct=0
for row in range(50):
  inputs = tokenizer(test_df['text'][row], return_tensors="pt", truncation=True, padding=True)
  outputs = model(**inputs)
  logits = outputs.logits
  pred = logits.argmax().item()
  sentiment_map = {0: "negative", 1: "neutral", 2: "positive"}
  print("Predicted Sentiment:", sentiment_map[pred], "True Sentiment : ",test_df['sentiment'][row])
  if sentiment_map[pred]==test_df['sentiment'][row]:
    correct+=1
print(correct/50)

